{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Neural Network for Handwritten Digits Recognition\n",
    "\n",
    "In this video, we'll create a neural network for discovering patterns in our data. After training, we'll be able to use the network to classify the digits contained in new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture\n",
    "\n",
    "Since our data points are vectors with 784 entries, the input layer will have 784 nodes. Let's start with two hidden layers, each containing 512 nodes. Our output layer has to distinguish between 10 different digits, so it will have 10 nodes. We'll use a softmax activation function in the output layer to obtain probabilities for each potential digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification\n",
    "\n",
    "We'll now specify this drafted model in Keras. We'll use a flatten layer to convert the image matrix's input to a vector. Then, we'll add two hidden layers with ReLU activation functions. Dropout layers will be added to minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for specifying the neural network model in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is a good starting point, but we'll make it even better by adding ReLU activation functions to all hidden layers and incorporating dropout layers to minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for improving the neural network model\n",
    "from keras.layers import ReLU\n",
    "\n",
    "improved_model = Sequential()\n",
    "improved_model.add(Flatten(input_shape=(28, 28)))\n",
    "improved_model.add(ReLU())\n",
    "improved_model.add(Dropout(0.2))\n",
    "improved_model.add(Dense(512))\n",
    "improved_model.add(ReLU())\n",
    "improved_model.add(Dropout(0.2))\n",
    "improved_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the improved model\n",
    "improved_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print improved model summary\n",
    "improved_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
