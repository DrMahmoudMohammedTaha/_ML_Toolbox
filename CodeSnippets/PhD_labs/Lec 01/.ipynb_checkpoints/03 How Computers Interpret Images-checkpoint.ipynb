{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digits Recognition using Deep Learning\n",
    "\n",
    "Let's begin by investigating how deep learning can be used to recognize handwritten numerical digits. We'll design an image classification algorithm that takes pictures of handwritten numbers and identifies the numbers represented in the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "To do this, we'll use the MNIST Database which contains 70000 grayscale images of handwritten digits. Each depicts one of the numbers zero through nine. This database is perhaps one of the most famous databases in the field of machine learning. We'll work with this dataset for the next few sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're strongly encouraged to follow along in the Jupyter notebook linked next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Any grayscale image is interpreted by the computer as a matrix with one entry for each image pixel. Each image in the MNIST Database is 28 pixels high and 28 pixels wide, and so understood by the computer as a 28 by 28 matrix. White pixels are encoded as 255. Black pixels are encoded as 0. And gray pixels appear in the matrix as an integer somewhere in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick preprocessing step, we'll rescale each image to instead have values in the range from 0 to 1. To do this, we'll divide every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before supplying the data to a deep network in Keras, we'll also need to preprocess the labels. Currently, each image has a label that's integer valued. We'll need to convert this to a one-hot encoding. Each label will be transformed to a vector with mostly zeros. If the label was originally a 7, we'll put a 1 in the seventh entry of the vector. Our second training image depicts a 3, so I'll put a 1 in the third entry of its label vector, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data appears to be sufficiently preprocessed, let's move on to building our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Recall that MLPs only take vectors as input. So in order to use an MLP with images, which are encoded as matrices, we have to first convert all of our matrices to vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of our 28 by 28 matrices, we will flatten them to a vector with 784 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for flattening images to vectors\n",
    "import numpy as np\n",
    "\n",
    "# Assuming img is your image matrix\n",
    "img_vector = np.reshape(img, (784,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
